# ğŸ”‘ MIT Logistics - ConfiguraÃ§Ã£o de API Keys

## ğŸ¯ Resumo
O sistema MIT Logistics v2.0 utiliza **OpenAI** e **Google Gemini** para processamento de consultas logÃ­sticas. Este guia explica como configurar as chaves API necessÃ¡rias.

## âš¡ ConfiguraÃ§Ã£o RÃ¡pida

### 1. Copie o arquivo de exemplo
```bash
cp .env.example .env
```

### 2. Edite o arquivo .env
```bash
nano .env
# ou
code .env
```

### 3. Configure suas chaves API
```env
# OpenAI (obtenha em: https://platform.openai.com/api-keys)
OPENAI_API_KEY=sk-proj-abc123...

# Gemini (obtenha em: https://aistudio.google.com/app/apikey)
GEMINI_API_KEY=AIzaSyAbc123...
```

### 4. Teste a configuraÃ§Ã£o
```bash
python3 test-config.py
```

### 5. Inicie o sistema
```bash
./start-system.sh
```

## ğŸŒ Formas de ConfiguraÃ§Ã£o

### ğŸ“ **MÃ©todo 1: Arquivo .env (Recomendado)**
Edite o arquivo `.env` na raiz do projeto:
```env
OPENAI_API_KEY=sk-proj-sua-chave-aqui
GEMINI_API_KEY=AIzaSy-sua-chave-aqui
```

### ğŸ–¥ï¸ **MÃ©todo 2: VariÃ¡veis de Ambiente**
**Linux/macOS:**
```bash
export OPENAI_API_KEY="sk-proj-sua-chave"
export GEMINI_API_KEY="AIzaSy-sua-chave"
```

**Windows:**
```cmd
set OPENAI_API_KEY=sk-proj-sua-chave
set GEMINI_API_KEY=AIzaSy-sua-chave
```

### ğŸŒ **MÃ©todo 3: Dashboard Web**
Acesse: `http://localhost:3000/settings/llm`
- Interface visual completa
- Teste de conectividade em tempo real
- Monitoramento de custos

## ğŸ”— Onde Obter as Chaves

### ğŸ¤– OpenAI API Key
1. Acesse: https://platform.openai.com/api-keys
2. FaÃ§a login/cadastro
3. Clique em "Create new secret key"
4. Copie a chave (comeÃ§a com `sk-proj-` ou `sk-`)

**Modelos DisponÃ­veis:**
- `gpt-3.5-turbo` (padrÃ£o, mais barato)
- `gpt-4` (mais avanÃ§ado, mais caro)
- `gpt-4-turbo` (mais rÃ¡pido)

### ğŸ’ Google Gemini API Key
1. Acesse: https://aistudio.google.com/app/apikey
2. FaÃ§a login com conta Google
3. Clique em "Create API key"
4. Copie a chave (comeÃ§a com `AIzaSy`)

**Modelos DisponÃ­veis:**
- `gemini-pro` (padrÃ£o)
- `gemini-pro-vision` (com suporte a imagens)

## âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### ğŸ›ï¸ ParÃ¢metros do LLM Router
```env
# Provedor preferido (auto = roteamento inteligente)
LLM_PREFERRED_PROVIDER=auto

# Limite diÃ¡rio de custo por provedor (USD)
LLM_MAX_DAILY_COST=50

# Temperatura (criatividade): 0.0-2.0
LLM_TEMPERATURE=0.3

# MÃ¡ximo de tokens por resposta
LLM_MAX_TOKENS=1000
```

### ğŸ”„ EstratÃ©gia de Roteamento
O sistema automaticamente escolhe o melhor provedor baseado no tipo de consulta:

| Tipo de Consulta | Provedor Preferido | Fallback |
|------------------|-------------------|----------|
| **LogÃ­stica** (CT-e, containers) | OpenAI | Gemini |
| **Financeiro** (custos, cÃ¢mbio) | Gemini | OpenAI |
| **Aduaneiro** (NCM, DI) | OpenAI | Gemini |
| **AnÃ¡lise** (relatÃ³rios) | OpenAI | Gemini |
| **Geral** | ConfigurÃ¡vel | AutomÃ¡tico |

## ğŸ” ValidaÃ§Ã£o e Teste

### âœ… Teste RÃ¡pido
```bash
# Teste bÃ¡sico de configuraÃ§Ã£o
python3 test-config.py

# Output esperado:
# âœ… OpenAI API key configurada
# âœ… Gemini API key configurada  
# âœ… ConfiguraÃ§Ã£o vÃ¡lida!
```

### ğŸ§ª Teste via Dashboard
1. Inicie o sistema: `./start-system.sh`
2. Acesse: `http://localhost:3000/settings/llm`
3. Clique em "ğŸ§ª Testar" para cada provedor
4. Verifique se retorna sucesso

### ğŸ“Š Monitoramento
O dashboard mostra em tempo real:
- âœ… Status dos provedores
- ğŸ’° Custo consumido hoje
- â±ï¸ Tempo mÃ©dio de resposta
- ğŸ“ˆ NÃºmero de requests
- âŒ Contagem de erros

## â— Requisitos MÃ­nimos

### ğŸ¯ ConfiguraÃ§Ã£o MÃ­nima
- **Pelo menos 1 API key** (OpenAI OU Gemini)
- ConexÃ£o com internet
- Python 3.9+

### ğŸ’° Custos Estimados
**OpenAI (GPT-3.5-turbo):**
- ~$0.002 por 1K tokens
- ~200-500 tokens por consulta
- ~$0.001-0.003 por consulta

**Gemini Pro:**
- ~$0.001 por 1K tokens  
- ~150-400 tokens por consulta
- ~$0.0005-0.002 por consulta

**Limite PadrÃ£o:** $50/dia por provedor

## ğŸš¨ SoluÃ§Ã£o de Problemas

### âŒ "Nenhuma API key configurada"
```bash
# Verifique se o arquivo .env existe
ls -la .env

# Verifique se as variÃ¡veis estÃ£o definidas
python3 test-config.py
```

### âŒ "API key invÃ¡lida"
- **OpenAI**: Deve comeÃ§ar com `sk-proj-` ou `sk-`
- **Gemini**: Deve comeÃ§ar com `AIzaSy`
- Verifique se nÃ£o hÃ¡ espaÃ§os extras

### âŒ "Rate limit exceeded"
- Aguarde alguns minutos
- Verifique se nÃ£o atingiu o limite diÃ¡rio
- Configure o limite em `LLM_MAX_DAILY_COST`

### âŒ "Connection error"
- Verifique sua conexÃ£o com internet
- Teste as APIs diretamente no dashboard

## ğŸ“ Suporte

- **Dashboard LLM**: `http://localhost:3000/settings/llm`
- **Logs do sistema**: `./start-system.sh` (veja output)
- **Teste de config**: `python3 test-config.py`

---

ğŸ’¡ **Dica**: Use o modo `auto` para roteamento inteligente e economia de custos!