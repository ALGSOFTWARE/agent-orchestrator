# ğŸš€ MIT Logistics - Guia de InicializaÃ§Ã£o

## ğŸ“‹ PrÃ©-requisitos

### 1. Node.js 18+
```bash
# Verificar se Node.js estÃ¡ instalado
node --version
npm --version
```

### 2. Ollama (para os agentes de IA)
```bash
# Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Ou no macOS com Homebrew
brew install ollama

# Iniciar o serviÃ§o Ollama
ollama serve

# Em outro terminal, baixar os modelos necessÃ¡rios
ollama pull llama3.2:3b
ollama pull mistral
```

### 3. Python 3.9+ (para o backend)
```bash
# Verificar se Python estÃ¡ instalado
python3 --version
pip3 --version
```

## ğŸƒâ€â™‚ï¸ Como Rodar o Sistema

### OpÃ§Ã£o 1: Script AutomÃ¡tico (Recomendado)
```bash
cd /home/narrador/Projetos/MIT
chmod +x start-system.sh
./start-system.sh
```

### OpÃ§Ã£o 2: Manual (Passo a Passo)

#### 1. Backend Python (Gatekeeper + APIs)
```bash
# Terminal 1 - Backend
cd /home/narrador/Projetos/MIT/python-crewai
pip3 install -r requirements.txt
python3 -m uvicorn api.main:app --host 0.0.0.0 --port 8001 --reload
```

#### 2. Frontend Next.js
```bash
# Terminal 2 - Frontend
cd /home/narrador/Projetos/MIT/frontend
npm install
npm run dev
```

#### 3. Verificar Ollama
```bash
# Terminal 3 - Verificar se Ollama estÃ¡ rodando
curl http://localhost:11434/api/version
```

## ğŸŒ URLs do Sistema

ApÃ³s iniciar tudo, acesse:

- **ğŸ–¥ï¸ Frontend Dashboard**: http://localhost:3000
- **ğŸ¤– Agent Tester**: http://localhost:3000/agents
- **ğŸ“Š Monitoring**: http://localhost:3000/monitoring
- **ğŸ›¡ï¸ Gatekeeper API**: http://localhost:8001
- **ğŸ§  Ollama API**: http://localhost:11434

## ğŸ”§ Troubleshooting

### Problema: Porta 3000 ocupada
```bash
# Matar processo na porta 3000
npx kill-port 3000
# Ou usar porta alternativa
npm run dev -- --port 3001
```

### Problema: Ollama nÃ£o conecta
```bash
# Verificar se Ollama estÃ¡ rodando
ps aux | grep ollama

# Reiniciar Ollama
pkill ollama
ollama serve
```

### Problema: DependÃªncias Python
```bash
# Reinstalar dependÃªncias
cd /home/narrador/Projetos/MIT/python-crewai
pip3 install --upgrade -r requirements.txt
```

## ğŸ¯ Primeiros Passos

1. **Acesse**: http://localhost:3000
2. **Clique em "ğŸ” Entrar"** na pÃ¡gina inicial
3. **Escolha um usuÃ¡rio teste** (ex: Admin ou Logistics)
4. **Explore**:
   - ğŸ¤– **Agent Tester**: Teste os agentes de IA
   - ğŸ“Š **Monitoring**: Veja mÃ©tricas em tempo real
   - ğŸ” **API Explorer**: Explore as APIs GraphQL

## ğŸ“± Funcionalidades DisponÃ­veis

### ğŸ” AutenticaÃ§Ã£o
- UsuÃ¡rios de teste prÃ©-configurados
- Diferentes nÃ­veis de permissÃ£o
- SimulaÃ§Ã£o de sessÃµes

### ğŸ¤– Agent Tester
- MIT Tracking Agent (logÃ­stica)
- Gatekeeper Agent (seguranÃ§a)
- Customs Agent (aduaneiro)
- Financial Agent (financeiro)

### ğŸ“Š Monitoring Dashboard
- Status dos serviÃ§os em tempo real
- MÃ©tricas de CPU, MemÃ³ria, Disco
- Logs de atividade
- Health checks automÃ¡ticos

## ğŸ› Logs e Debug

### Frontend (Next.js)
```bash
# Ver logs do frontend
cd /home/narrador/Projetos/MIT/frontend
npm run dev
```

### Backend (Python)
```bash
# Ver logs do backend
cd /home/narrador/Projetos/MIT/python-crewai
python3 -m uvicorn api.main:app --host 0.0.0.0 --port 8001 --reload --log-level debug
```

### Ollama
```bash
# Ver logs do Ollama
ollama logs
```

## ğŸ“ Suporte

Se encontrar problemas:
1. Verifique se todas as portas estÃ£o livres
2. Confirme que Ollama estÃ¡ rodando com os modelos
3. Verifique os logs de cada serviÃ§o
4. Reinicie os serviÃ§os se necessÃ¡rio

**Sistema testado em**: Ubuntu 20.04+, macOS 12+, Windows 11 (WSL2)